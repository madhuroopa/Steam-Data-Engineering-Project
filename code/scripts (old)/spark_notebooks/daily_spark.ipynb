{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInput File:\\n    - daily_data/ *.csv\\n\\nProduces the following csv files:\\n    - top_20\\n    - top_free\\n    - top_not_free\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Code to process Daily Data\n",
    "\n",
    "'''\n",
    "Input File:\n",
    "    - daily_data/ *.csv\n",
    "\n",
    "Produces the following csv files:\n",
    "    - top_20\n",
    "    - top_free\n",
    "    - top_not_free\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "spark = SparkSession.builder.appName('daily_spark').getOrCreate()\n",
    "#spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType\n",
    "\n",
    "# Define schema for our data using DDL\n",
    "schema = StructType([\n",
    "    StructField(\"Rank\", IntegerType(), True),\n",
    "    StructField(\"Game Name\", StringType(), True),\n",
    "    StructField(\"Free to Play\", IntegerType(), True),\n",
    "    StructField(\"Current Players\", IntegerType(), True),\n",
    "    StructField(\"Peek Today\", IntegerType(), True),\n",
    "    StructField(\"Collection Date\", DateType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_DATA_PATH = r'../data/daily_data/most_played/' \n",
    "files = os.listdir(DAILY_DATA_PATH)\n",
    "\n",
    "FILE_DATE = None\n",
    "try:\n",
    "    csv_file = [f for f in files if f.endswith('.csv')]\n",
    "    file = csv_file[0]\n",
    "    most_daily_played = spark.read.csv(DAILY_DATA_PATH + file, header=True, schema=schema)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while reading the JSON file:\", e)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Rank: int, Game Name: string, Free to Play: int, Current Players: int, Peek Today: int, Collection Date: date]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning Game Name\n",
    "from pyspark.sql.functions import regexp_replace, col\n",
    "special_characters = [\"™\", \"®\"]\n",
    "\n",
    "for char in special_characters:\n",
    "    most_daily_played = most_daily_played.withColumn(\"Game Name\", regexp_replace(col(\"Game Name\"), char, \"\"))\n",
    "\n",
    "most_daily_played.cache()\n",
    "#most_daily_played.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter free to play games and create a new DataFrame\n",
    "free_to_play_df = most_daily_played.filter(most_daily_played[\"Free to Play\"] == 1)\n",
    "not_free_to_play_df = most_daily_played.filter(most_daily_played[\"Free to Play\"] == 0)\n",
    "\n",
    "# Sort by Peek Today\n",
    "free_to_play_sorted = free_to_play_df.orderBy(\"Peek Today\")\n",
    "not_free_to_play_sorted = not_free_to_play_df.orderBy(\"Peek Today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_top_20 = r\"../saved_data/daily_data/top_20\"\n",
    "path_top_free = r\"../saved_data/daily_data/top_free\"\n",
    "path_top_not_free = r\"../saved_data/daily_data/top_not_free\"\n",
    "\n",
    "# Save the DataFrame as CSV\n",
    "most_daily_played.write.format(\"csv\").mode(\"overwrite\").option(\"header\", \"true\").save(path_top_20)\n",
    "free_to_play_sorted.write.format(\"csv\").mode(\"overwrite\").option(\"header\", \"true\").save(path_top_free)\n",
    "not_free_to_play_sorted.write.format(\"csv\").mode(\"overwrite\").option(\"header\", \"true\").save(path_top_not_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
